{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0d5904-3035-4d89-be44-835ee06cf2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da859556-d21a-4b1e-8bf1-76abd515f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, D = 20, 128, 378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873f2df1-8ac3-41b0-93e1-dc7020b25728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y[:, 0] = X[:, 0]\n",
    "# Y[:, t] = A[:, t-1] * Y[:, t-1] + X[:, t]\n",
    "\n",
    "def pscan_fft(A, X):\n",
    "    N, T, D = X.shape\n",
    "\n",
    "    # A_log \\in [N x T]\n",
    "    A_log = torch.log(A.to(dtype=torch.cfloat))\n",
    "    # A_log_T \\in [T x N]\n",
    "    A_log_T = A_log.T\n",
    "    # A_log_T \\in [(2T - 1) x N]\n",
    "    A_log_T = torch.cat([A_log_T, torch.zeros(T - 1, N)], dim=0)\n",
    "\n",
    "    # For T = 3\n",
    "    # mask1 = [1, 1, 1, 0, 0]\n",
    "    # circulant_matrix = [\n",
    "    #    [1, 0, 0, 1, 1],\n",
    "    #    [1, 1, 0, 0, 1],\n",
    "    #    [1, 1, 1, 0, 0],\n",
    "    #    [0, 1, 1, 1, 0],\n",
    "    #    [0, 0, 1, 1, 1],\n",
    "    # ]\n",
    "    mask1 = torch.where(\n",
    "        (torch.arange(2 * T - 1) <= T - 1),\n",
    "        1, \n",
    "        0\n",
    "    )\n",
    "    mask1 = mask1.unsqueeze(1)\n",
    "    Z1_log_rev = torch.fft.ifft(\n",
    "        torch.fft.fft(mask1, dim=0) * torch.fft.fft(A_log_T, dim=0),\n",
    "        n=2 * T - 1,\n",
    "        dim=0\n",
    "    )\n",
    "    # Since we add T - 1 of padding zeros to A_log_T\n",
    "    Z1_log_rev = Z1_log_rev[:T, :].T.unsqueeze(-1)\n",
    "\n",
    "    # For T = 4 and t = 2\n",
    "    # mask2[0] = [0, 0, 0, 0, 0, 0, 0]\n",
    "    # mask2[1] = [0, 1, 0, 0, 0, 0, 0]\n",
    "    # mask2[2] = [0, 1, 1, 0, 0, 0, 0]\n",
    "    # mask2[3] = [0, 1, 1, 1, 0, 0, 0]\n",
    "    #\n",
    "    # for t = 2\n",
    "    # circulant_matrix = [\n",
    "    #    [0, 0, 0, 0, 0, 1, 1],\n",
    "    #    [1, 0, 0, 0, 0, 0, 1],\n",
    "    #    [1, 1, 0, 0, 0, 0, 0],\n",
    "    #    [0, 1, 1, 0, 0, 0, 0],\n",
    "    #    [0, 0, 1, 0, 0, 0, 0],\n",
    "    #    [0, 0, 0, 1, 0, 0, 0],\n",
    "    #    [0, 0, 0, 1, 1, 0, 0],\n",
    "    # ]\n",
    "    mask2 = torch.where(\n",
    "        torch.cat([\n",
    "            ((torch.arange(2 * T - 1) >= 1) & (torch.arange(2 * T - 1) <= t)).unsqueeze(0) for t in range(T)\n",
    "        ], dim=0),\n",
    "        1, \n",
    "        0\n",
    "    )\n",
    "    mask2 = mask2.unsqueeze(-1)\n",
    "    Z2_log_rev = torch.fft.ifft(\n",
    "        torch.fft.fft(mask2, dim=1) * torch.fft.fft(A_log_T.unsqueeze(0), dim=1), \n",
    "        n=2 * T - 1,\n",
    "        dim=1\n",
    "    )\n",
    "    # Since we add T - 1 of padding zeros to A_log_T\n",
    "    Z2_log_rev = Z2_log_rev[:, :T, :]\n",
    "    Z2_log_rev = Z2_log_rev.permute(2, 0, 1)\n",
    "    # Fixing the problem casued by line 3 in the example\n",
    "    Z2_log_rev = torch.tril(Z2_log_rev, diagonal=0)\n",
    "    \n",
    "    Z_log = Z1_log_rev - Z2_log_rev\n",
    "    # Z \\in [N x T x T]\n",
    "    Z = torch.tril(torch.exp(Z_log), diagonal=0)\n",
    "    # After exp we no longer have complex components\n",
    "    Z = Z.real\n",
    "    # Y \\in [N x T x D] = bmm([N x T x T], [N x T x D])\n",
    "    Y_ = torch.bmm(Z, X)\n",
    "    Y_ = torch.cat([torch.zeros(N, 1, D), Y_[:, :-1, :]], dim=1) \n",
    "    Y = Y_ + X\n",
    "    return Y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5870ff8-e3da-49aa-aaea-ac157b231cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(N, T).requires_grad_() / 10\n",
    "X = torch.randn(N, T, D).requires_grad_() / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d204895c-82bd-4df8-b3e5-01cef331b8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3222e-06, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_Y(A, X):\n",
    "    Y_fft = pscan_fft(A, X)\n",
    "    \n",
    "    Y_expected = torch.zeros(N, T, D)\n",
    "    Y_expected[:, 0, :] = X[:, 0, :]\n",
    "    for k in range(1, X.shape[1]):\n",
    "        Y_expected[:, k, :] = A[:, k - 1].unsqueeze(1) * Y_expected[:, k - 1, :] + X[:, k, :]\n",
    "    \n",
    "    return torch.norm(Y_fft - Y_expected)\n",
    "\n",
    "test_Y(A=A, X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ee7ff1-1457-4daf-abaf-ac4fdac7ea72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9501e-05, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_Z1(A, X):\n",
    "    A_T = A.T\n",
    "    A_T = torch.cat([A_T, torch.zeros(T - 1, N)], dim=0)\n",
    "    \n",
    "    mask2 = torch.where(\n",
    "        torch.cat([\n",
    "            ((torch.arange(2 * T - 1) >= 1) & (torch.arange(2 * T - 1) <= t)).unsqueeze(0) for t in range(T)\n",
    "        ], dim=0),\n",
    "        1, \n",
    "        0\n",
    "    )\n",
    "    mask2 = mask2.unsqueeze(-1)\n",
    "    \n",
    "    Z2_ = torch.fft.irfft(\n",
    "        torch.fft.rfft(mask2, dim=1) * torch.fft.rfft(A_T.unsqueeze(0), dim=1), \n",
    "        n=2 * T - 1,\n",
    "        dim=1\n",
    "    )\n",
    "    Z2_fft = Z2_[:, :T, :]\n",
    "    \n",
    "    def C(t):\n",
    "        C_ = torch.tril(torch.ones(t, t), diagonal=-1) \n",
    "        C_ = torch.cat([C_, torch.zeros(t, T - t)], dim=-1)\n",
    "        C_ = torch.cat([C_, torch.zeros(T - t, T)], dim=0)\n",
    "        return C_\n",
    "    \n",
    "    Z2_expected = torch.zeros(T, T, N)\n",
    "    for t in range(1, T + 1):\n",
    "        Z2_expected[t - 1, :, :] = C(t) @ A.T\n",
    "\n",
    "    return torch.norm(Z2_expected.permute(2, 0, 1) - torch.tril(Z2_fft.permute(2, 0, 1), diagonal=0))\n",
    "\n",
    "test_Z1(A=A, X=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4772b93d-1a9d-45f4-b165-7cbd4f56cdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1853e-06, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_Z1(A, X):\n",
    "    mask1 = torch.where(\n",
    "        (torch.arange(2 * T - 1) <= T - 1),\n",
    "        1, \n",
    "        0\n",
    "    )\n",
    "    mask1 = mask1.unsqueeze(1)\n",
    "    \n",
    "    A_T = A.T\n",
    "    A_T = torch.cat([A_T, torch.zeros(T - 1, N)], dim=0)\n",
    "    Z1_ = torch.fft.irfft(\n",
    "        torch.fft.rfft(mask1, dim=0) * torch.fft.rfft(A_T, dim=0),\n",
    "        n=2 * T - 1,\n",
    "        dim=0\n",
    "    )\n",
    "    Z1_ = Z1_[:T, :]\n",
    "    \n",
    "    Z1 = torch.tril(torch.ones(T, T), diagonal=0) @ A.T\n",
    "\n",
    "    return torch.norm(Z1_ - Z1)\n",
    "\n",
    "test_Z1(A=A, X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbeef63-e464-4d7f-b739-5cecaa11dfec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b79ec-6009-406e-8b55-deeeb56d8fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
